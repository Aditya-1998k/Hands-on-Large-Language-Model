
## Tokens & Embeddings
Tokens and Embeddings are two central concepts of using LLMs.
They provide clear sense how AI works and how LLM 

&nbsp;&nbsp;&nbsp;&nbsp;<img src="https://github.com/user-attachments/assets/b000b1a6-1fa3-4aaa-bd70-1f8953eb83b2" alt="image" width="600" height="384">

- Token == Breaking down the sentences
- Embeddings == Converting tokens into numeric representation (vectors)

### LLM Tokenization
Before propmt is presented to the LLM, first it have to be go through the tokenizer that breaks it into the peices.

Example showing the tokenizer of GPT-4 on the OpenAI Platform

&nbsp;&nbsp;&nbsp;&nbsp;<img width="600" height="431" alt="image" src="https://github.com/user-attachments/assets/4cddf1b8-e56b-4e95-a2da-59ec32c35826" />
